{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 11:50:48.927309: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-29 11:50:48.927802: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(mnist_train, mnist_test), ds_info = tfds.load('mnist', split=['train', 'test'], as_supervised=True, with_info=True)\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "def transform_labels(image, label):\n",
    "  return image, tf.math.floor(label / 2)\n",
    "\n",
    "def prepare(ds, shuffle=True, batch_size=32, prefetch=True):\n",
    "  ds = ds.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  ds = ds.map(transform_labels, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  ds = ds.shuffle(ds_info.splits['train'].num_examples) if shuffle else ds\n",
    "  ds = ds.cache()\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(tf.data.experimental.AUTOTUNE) if prefetch else ds\n",
    "  return ds\n",
    "\n",
    "def split_tasks(ds, predicate):\n",
    "  return ds.filter(predicate), ds.filter(lambda img, label: not predicate(img, label))\n",
    "\n",
    "multi_task_train, multi_task_test = prepare(mnist_train), prepare(mnist_test)\n",
    "task_A_train, task_B_train = split_tasks(mnist_train, lambda img, label: label % 2 == 0)\n",
    "task_A_train, task_B_train = prepare(task_A_train), prepare(task_B_train)\n",
    "task_A_test, task_B_test = split_tasks(mnist_test, lambda img, label: label % 2 == 0)\n",
    "task_A_test, task_B_test = prepare(task_A_test), prepare(task_B_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_set):\n",
    "  acc = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "  for i, (imgs, labels) in enumerate(test_set):\n",
    "    preds = model.predict_on_batch(imgs)\n",
    "    acc.update_state(labels, preds)\n",
    "  return acc.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        input= tf.keras.Input(shape=(28, 28, 1))\n",
    "        l1=tf.keras.layers.Dense(128, activation='relu')(input)\n",
    "        self.feature_extractor=tf.keras.Model(input,l1)\n",
    "\n",
    "        self.fc=tf.keras.layers.Dense(1)\n",
    "\n",
    "        self.model=tf.keras.Model(input,self.fc(self.feature_extractor(input)))\n",
    "\n",
    "        self.model.build(input_shape=(None, 28, 28, 1))\n",
    "\n",
    "        # self.model= tf.keras.Model(input,self.fc)\n",
    "\n",
    "\n",
    "        self.n_classes=1\n",
    "        self.classes=[]\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "    def fit_existing_model(self,dataset, epochs=10):\n",
    "        self.model.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        self.model.fit(dataset, epochs=epochs)\n",
    "\n",
    "    def update_model(self,dataset):\n",
    "        new_classes=[]\n",
    "        for i, (imgs, labels) in enumerate(dataset):\n",
    "            for label in labels:\n",
    "                if label not in new_classes:\n",
    "                    new_classes.append(label.numpy())\n",
    "        new_n=len(new_classes)\n",
    "        new_size=self.n_classes+new_n\n",
    "\n",
    "\n",
    "        prev_model=copy.deepcopy(self)\n",
    "        weights_old=self.fc.get_weights()[0]\n",
    "\n",
    "        new_layer=tf.keras.layers.Dense(new_size,kernel_initializer='random_normal',bias_initializer='zeros')\n",
    "        new_layer.build(input_shape=self.feature_extractor.output_shape[1:])\n",
    "        # print(new_layer.get_weights())\n",
    "        weights_new=new_layer.get_weights()[0]\n",
    "        print(weights_new.shape)\n",
    "        print(weights_old.shape)\n",
    "        weights_new[:,:self.n_classes]=weights_old\n",
    "        weights_new_final=[weights_new,new_layer.get_weights()[1]]\n",
    "        new_layer.set_weights(weights_new_final)\n",
    "\n",
    "        accuracy = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "        loss_cls = tf.keras.metrics.SparseCategoricalCrossentropy('loss')\n",
    "        loss_dist = tf.keras.metrics.SparseCategoricalCrossentropy('loss')\n",
    "\n",
    "        self.model.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        for epoch in range(15):\n",
    "\n",
    "            accuracy.reset_states()\n",
    "            loss_cls.reset_states()\n",
    "            loss_dist.reset_states()\n",
    "            for i, (imgs, labels) in enumerate(dataset):\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    logits = self.model.predict(imgs)\n",
    "                    cls_loss = self.model.loss(labels, logits)\n",
    "                          \n",
    "                    # dist_target= prev_model.forward(imgs)\n",
    "                    # logits_dist=logits[:,:-len(new_classes)]\n",
    "                    # dist_loss=loss_dist(dist_target,logits_dist)\n",
    "\n",
    "                    loss_value = cls_loss #+ dist_loss\n",
    "                grads=tape.gradient(loss_value, self.model.trainable_variables)\n",
    "                self.model.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "\n",
    "        self.n_classes=new_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 6)\n",
      "(128, 1)\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "No gradient defined for operation 'IteratorGetNext' (op type: IteratorGetNext)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/miniforge3/envs/genomics/lib/python3.8/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    605\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             \u001b[0mgrad_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradient_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/genomics/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_gradient_function\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2731\u001b[0m     \u001b[0mop_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2732\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgradient_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/genomics/lib/python3.8/site-packages/tensorflow/python/framework/registry.py\u001b[0m in \u001b[0;36mlookup\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m       raise LookupError(\n\u001b[0m\u001b[1;32m    100\u001b[0m           \"%s registry has no entry for: %s\" % (self._name, name))\n",
      "\u001b[0;31mLookupError\u001b[0m: gradient registry has no entry for: IteratorGetNext",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/st/g0z4v7q50sj7prs3cygcjp6m0000gn/T/ipykernel_19100/3462068493.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_A_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/st/g0z4v7q50sj7prs3cygcjp6m0000gn/T/ipykernel_19100/1431451870.py\u001b[0m in \u001b[0;36mupdate_model\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                     \u001b[0mcls_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/genomics/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1749\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/genomics/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/genomics/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    954\u001b[0m               *args, **kwds)\n\u001b[1;32m    955\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m       return self._concrete_stateful_fn._call_flat(\n\u001b[0m\u001b[1;32m    957\u001b[0m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/genomics/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1967\u001b[0m         \u001b[0mpossible_gradient_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m         executing_eagerly)\n\u001b[0;32m-> 1969\u001b[0;31m     \u001b[0mforward_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_with_tangents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1970\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m       flat_outputs = forward_function.call(\n",
      "\u001b[0;32m~/miniforge3/envs/genomics/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1492\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m     \u001b[0;34m\"\"\"Builds or retrieves a forward function for this call.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m     forward_function = self._functions.forward(\n\u001b[0m\u001b[1;32m   1495\u001b[0m         self._inference_args, self._input_tangents)\n\u001b[1;32m   1496\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_tangents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/genomics/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inference_args, input_tangents)\u001b[0m\n\u001b[1;32m   1224\u001b[0m       (self._forward, self._forward_graph, self._backward,\n\u001b[1;32m   1225\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forwardprop_output_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_forwardprop_outputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m            self._forward_and_backward_functions(inference_args, input_tangents))\n\u001b[0m\u001b[1;32m   1227\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/genomics/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_forward_and_backward_functions\u001b[0;34m(self, inference_args, input_tangents)\u001b[0m\n\u001b[1;32m   1375\u001b[0m     \"\"\"\n\u001b[1;32m   1376\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_inference_outputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m     return self._build_functions_for_outputs(\n\u001b[0m\u001b[1;32m   1378\u001b[0m         outputs, inference_args, input_tangents)\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/genomics/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_build_functions_for_outputs\u001b[0;34m(self, outputs, inference_args, input_tangents)\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0mgradients_wrt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m         gradients_wrt_inputs = gradients_util._GradientsHelper(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    945\u001b[0m             \u001b[0mtrainable_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/genomics/lib/python3.8/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    632\u001b[0m               \u001b[0mgrad_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_grad_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m               raise LookupError(\n\u001b[0m\u001b[1;32m    635\u001b[0m                   \u001b[0;34m\"No gradient defined for operation '%s' (op type: %s)\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                   (op.name, op.type))\n",
      "\u001b[0;31mLookupError\u001b[0m: No gradient defined for operation 'IteratorGetNext' (op type: IteratorGetNext)"
     ]
    }
   ],
   "source": [
    "model=Model()\n",
    "\n",
    "model.update_model(task_A_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(32, 28, 28, 1)\n",
      "(30, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "for i, (imgs, labels) in enumerate(task_A_test):\n",
    "    print((imgs.numpy()).shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8eda46fcdaf684ca6c615bf0acdae196e42139c0edab1eb57e328e85edfac349"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('genomics')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
